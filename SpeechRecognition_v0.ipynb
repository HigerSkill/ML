{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa as lr\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./train/audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mfcc(file_path, max_len=11):\n",
    "    y, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "    y = y[::3]\n",
    "    mfcc = librosa.feature.mfcc(y, sr=16000)\n",
    "    \n",
    "    if (max_len > mfcc.shape[1]):\n",
    "        pad_width = max_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_len]\n",
    "    \n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "def save_data(path=DATA_PATH):\n",
    "    names = os.listdir(path)\n",
    "    \n",
    "    for name in names:\n",
    "        mfcc_list = []\n",
    "        files = [path + name + '/' + file for file in os.listdir(path + '/' + name)]\n",
    "        for file in tqdm(files, \"Saving vectors of label - '{}'\".format(name)):\n",
    "            mfcc = to_mfcc(file)\n",
    "            mfcc_list.append(mfcc)\n",
    "        np.save(name + '.npy', mfcc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "    path=DATA_PATH\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "\n",
    "    X = np.load(labels[0] + '.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'bed': 100%|██████████| 1713/1713 [00:13<00:00, 125.93it/s]\n",
      "Saving vectors of label - 'cat': 100%|██████████| 1733/1733 [00:13<00:00, 127.55it/s]\n",
      "Saving vectors of label - 'dog': 100%|██████████| 1746/1746 [00:13<00:00, 128.04it/s]\n",
      "Saving vectors of label - 'happy': 100%|██████████| 1742/1742 [00:13<00:00, 128.27it/s]\n",
      "Saving vectors of label - 'house': 100%|██████████| 1750/1750 [00:13<00:00, 126.72it/s]\n"
     ]
    }
   ],
   "source": [
    "save_data()\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "X_train = X_train.reshape(X_train.shape[0], 20, 11, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 20, 11, 1)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "X_train = X_train.reshape(X_train.shape[0], 20, 11, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 20, 11, 1)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_v2():\n",
    "    weight_decay = 1e-4\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(2,2), padding='same', \n",
    "                     activation='elu', kernel_regularizer=regularizers.l2(weight_decay),\n",
    "                     input_shape=(20,11,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(2,2), activation='elu',\n",
    "                    kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    model.add(Dropout(0.2))\n",
    "   \n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (2,2), padding='same', activation='elu',\n",
    "                     kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (2,2), padding='same', activation='elu',\n",
    "                     kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    optimizer = rmsprop(lr=0.001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath, model):\n",
    "    sample = to_mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, 20, 11, 1)\n",
    "    return get_labels()[0][np.argmax(model.predict(sample_reshaped))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 20, 11, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 20, 11, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 19, 10, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 19, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 9, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 9, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 9, 5, 64)          8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 9, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 5, 64)          16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 9, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 4, 2, 128)         32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 2, 128)         65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 4, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 263,493\n",
      "Trainable params: 262,597\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 5210 samples, validate on 3474 samples\n",
      "Epoch 1/50\n",
      "5210/5210 [==============================] - 3s 574us/step - loss: 2.0335 - acc: 0.2697 - val_loss: 1.3647 - val_acc: 0.4787\n",
      "Epoch 2/50\n",
      "5210/5210 [==============================] - 1s 144us/step - loss: 1.4527 - acc: 0.4155 - val_loss: 1.0066 - val_acc: 0.6396\n",
      "Epoch 3/50\n",
      "5210/5210 [==============================] - 1s 140us/step - loss: 1.1485 - acc: 0.5687 - val_loss: 0.9618 - val_acc: 0.6514\n",
      "Epoch 4/50\n",
      "5210/5210 [==============================] - 1s 141us/step - loss: 0.9582 - acc: 0.6486 - val_loss: 0.7536 - val_acc: 0.7487\n",
      "Epoch 5/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.8056 - acc: 0.7146 - val_loss: 0.5571 - val_acc: 0.8129\n",
      "Epoch 6/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.7152 - acc: 0.7570 - val_loss: 0.5204 - val_acc: 0.8336\n",
      "Epoch 7/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.6296 - acc: 0.7848 - val_loss: 0.4409 - val_acc: 0.8607\n",
      "Epoch 8/50\n",
      "5210/5210 [==============================] - 1s 145us/step - loss: 0.5480 - acc: 0.8157 - val_loss: 0.3939 - val_acc: 0.8771\n",
      "Epoch 9/50\n",
      "5210/5210 [==============================] - 1s 141us/step - loss: 0.5060 - acc: 0.8374 - val_loss: 0.3473 - val_acc: 0.8938\n",
      "Epoch 10/50\n",
      "5210/5210 [==============================] - 1s 141us/step - loss: 0.4531 - acc: 0.8560 - val_loss: 0.3535 - val_acc: 0.8898\n",
      "Epoch 11/50\n",
      "5210/5210 [==============================] - 1s 147us/step - loss: 0.4214 - acc: 0.8655 - val_loss: 0.3165 - val_acc: 0.9062\n",
      "Epoch 12/50\n",
      "5210/5210 [==============================] - 1s 147us/step - loss: 0.3827 - acc: 0.8868 - val_loss: 0.2967 - val_acc: 0.9165\n",
      "Epoch 13/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.3565 - acc: 0.8925 - val_loss: 0.3004 - val_acc: 0.9099\n",
      "Epoch 14/50\n",
      "5210/5210 [==============================] - 1s 139us/step - loss: 0.3534 - acc: 0.8921 - val_loss: 0.3204 - val_acc: 0.9056\n",
      "Epoch 15/50\n",
      "5210/5210 [==============================] - 1s 141us/step - loss: 0.3278 - acc: 0.9006 - val_loss: 0.2742 - val_acc: 0.9203\n",
      "Epoch 16/50\n",
      "5210/5210 [==============================] - 1s 147us/step - loss: 0.3039 - acc: 0.9084 - val_loss: 0.2556 - val_acc: 0.9295\n",
      "Epoch 17/50\n",
      "5210/5210 [==============================] - 1s 148us/step - loss: 0.2877 - acc: 0.9127 - val_loss: 0.3167 - val_acc: 0.9070\n",
      "Epoch 18/50\n",
      "5210/5210 [==============================] - 1s 142us/step - loss: 0.2674 - acc: 0.9217 - val_loss: 0.2456 - val_acc: 0.9338\n",
      "Epoch 19/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.2763 - acc: 0.9190 - val_loss: 0.2319 - val_acc: 0.9358\n",
      "Epoch 20/50\n",
      "5210/5210 [==============================] - 1s 145us/step - loss: 0.2487 - acc: 0.9296 - val_loss: 0.2439 - val_acc: 0.9352\n",
      "Epoch 21/50\n",
      "5210/5210 [==============================] - 1s 149us/step - loss: 0.2347 - acc: 0.9324 - val_loss: 0.2437 - val_acc: 0.9306\n",
      "Epoch 22/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.2288 - acc: 0.9313 - val_loss: 0.2920 - val_acc: 0.9206\n",
      "Epoch 23/50\n",
      "5210/5210 [==============================] - 1s 147us/step - loss: 0.2195 - acc: 0.9338 - val_loss: 0.2680 - val_acc: 0.9312\n",
      "Epoch 24/50\n",
      "5210/5210 [==============================] - 1s 145us/step - loss: 0.2024 - acc: 0.9420 - val_loss: 0.2718 - val_acc: 0.9315\n",
      "Epoch 25/50\n",
      "5210/5210 [==============================] - 1s 144us/step - loss: 0.2059 - acc: 0.9434 - val_loss: 0.2782 - val_acc: 0.9295\n",
      "Epoch 26/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.2042 - acc: 0.9463 - val_loss: 0.2903 - val_acc: 0.9269\n",
      "Epoch 27/50\n",
      "5210/5210 [==============================] - 1s 149us/step - loss: 0.1928 - acc: 0.9461 - val_loss: 0.2250 - val_acc: 0.9433\n",
      "Epoch 28/50\n",
      "5210/5210 [==============================] - 1s 145us/step - loss: 0.1688 - acc: 0.9551 - val_loss: 0.2392 - val_acc: 0.9436\n",
      "Epoch 29/50\n",
      "5210/5210 [==============================] - 1s 142us/step - loss: 0.1896 - acc: 0.9495 - val_loss: 0.2366 - val_acc: 0.9396\n",
      "Epoch 30/50\n",
      "5210/5210 [==============================] - 1s 147us/step - loss: 0.1627 - acc: 0.9566 - val_loss: 0.2245 - val_acc: 0.9456\n",
      "Epoch 31/50\n",
      "5210/5210 [==============================] - 1s 147us/step - loss: 0.1721 - acc: 0.9553 - val_loss: 0.2392 - val_acc: 0.9421\n",
      "Epoch 32/50\n",
      "5210/5210 [==============================] - 1s 150us/step - loss: 0.1727 - acc: 0.9585 - val_loss: 0.2445 - val_acc: 0.9427\n",
      "Epoch 33/50\n",
      "5210/5210 [==============================] - 1s 150us/step - loss: 0.1626 - acc: 0.9572 - val_loss: 0.2252 - val_acc: 0.9450\n",
      "Epoch 34/50\n",
      "5210/5210 [==============================] - 1s 145us/step - loss: 0.1461 - acc: 0.9641 - val_loss: 0.2320 - val_acc: 0.9456\n",
      "Epoch 35/50\n",
      "5210/5210 [==============================] - 1s 146us/step - loss: 0.1363 - acc: 0.9662 - val_loss: 0.2754 - val_acc: 0.9419\n",
      "Epoch 36/50\n",
      "5210/5210 [==============================] - 1s 144us/step - loss: 0.1494 - acc: 0.9630 - val_loss: 0.2473 - val_acc: 0.9447\n",
      "Epoch 37/50\n",
      "5210/5210 [==============================] - 1s 142us/step - loss: 0.1533 - acc: 0.9616 - val_loss: 0.2618 - val_acc: 0.9462\n",
      "Epoch 38/50\n",
      "5210/5210 [==============================] - 1s 146us/step - loss: 0.1390 - acc: 0.9668 - val_loss: 0.2496 - val_acc: 0.9424\n",
      "Epoch 39/50\n",
      "5210/5210 [==============================] - 1s 146us/step - loss: 0.1295 - acc: 0.9683 - val_loss: 0.2506 - val_acc: 0.9444\n",
      "Epoch 40/50\n",
      "5210/5210 [==============================] - 1s 147us/step - loss: 0.1265 - acc: 0.9710 - val_loss: 0.2640 - val_acc: 0.9401\n",
      "Epoch 41/50\n",
      "5210/5210 [==============================] - 1s 145us/step - loss: 0.1182 - acc: 0.9718 - val_loss: 0.2296 - val_acc: 0.9459\n",
      "Epoch 42/50\n",
      "5210/5210 [==============================] - 1s 147us/step - loss: 0.1176 - acc: 0.9727 - val_loss: 0.2792 - val_acc: 0.9419\n",
      "Epoch 43/50\n",
      "5210/5210 [==============================] - 1s 144us/step - loss: 0.1261 - acc: 0.9722 - val_loss: 0.2735 - val_acc: 0.9444\n",
      "Epoch 44/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.1189 - acc: 0.9743 - val_loss: 0.2665 - val_acc: 0.9496\n",
      "Epoch 45/50\n",
      "5210/5210 [==============================] - 1s 144us/step - loss: 0.1191 - acc: 0.9708 - val_loss: 0.2436 - val_acc: 0.9522\n",
      "Epoch 46/50\n",
      "5210/5210 [==============================] - 1s 149us/step - loss: 0.1146 - acc: 0.9749 - val_loss: 0.2490 - val_acc: 0.9453\n",
      "Epoch 47/50\n",
      "5210/5210 [==============================] - 1s 143us/step - loss: 0.1150 - acc: 0.9741 - val_loss: 0.2563 - val_acc: 0.9485\n",
      "Epoch 48/50\n",
      "5210/5210 [==============================] - 1s 142us/step - loss: 0.1127 - acc: 0.9777 - val_loss: 0.2347 - val_acc: 0.9514\n",
      "Epoch 49/50\n",
      "5210/5210 [==============================] - 1s 149us/step - loss: 0.1063 - acc: 0.9770 - val_loss: 0.2699 - val_acc: 0.9470\n",
      "Epoch 50/50\n",
      "5210/5210 [==============================] - 1s 149us/step - loss: 0.1171 - acc: 0.9743 - val_loss: 0.2830 - val_acc: 0.9442\n",
      "3474/3474 [==============================] - 0s 111us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2829515112582197, 0.9441565918593003]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model_v2()\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train_hot, batch_size=128, epochs=50, verbose=1, validation_data=(X_test, y_test_hot))\n",
    "model.evaluate(X_test, y_test_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed\n"
     ]
    }
   ],
   "source": [
    "print(predict('./1.wav', model=model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
