{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"D:\\cv_corpus_v1\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CSV():\n",
    "    eval_data = pd.read_csv(DATA_PATH + \"cv-valid-dev.csv\")\n",
    "    train_data = pd.read_csv(DATA_PATH + \"cv-valid-train.csv\")\n",
    "    test_data = pd.read_csv(DATA_PATH + \"cv-valid-test.csv\")\n",
    "    \n",
    "    return eval_data, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wave(information, absolute=False):\n",
    "    data = information[1] # get a dict\n",
    "    audio, sr = librosa.load(DATA_PATH+str(data.filename), mono=True, sr=16000)\n",
    "    \n",
    "    return audio, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data, train_data, test_data = load_CSV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'abcdefghijklmnopqrstuvwxyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequenceLength(original_lengths, params):\n",
    "    return tf.cast(tf.floor((tf.cast(original_lengths, dtype=tf.float32) - params['n_fft']) / params['frame_step']\n",
    "                           ) + 1, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels, params):\n",
    "    # char to id\n",
    "    characters = list(params['alphabet'])\n",
    "    \n",
    "    table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(characters, list(range(len(characters)))), -1)\n",
    "    \n",
    "    return table.lookup(tf.string_split(labels, delimiter=''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_codes(codes, params):\n",
    "    # id to char\n",
    "    characters = list(params['alphabet'])\n",
    "    \n",
    "    table = tf.contrib.lookup.HashTable(tf.contrib.lookup.KeyValueTensorInitializer(list(range(len(characters))), characters), '')\n",
    "    \n",
    "    return table.lookup(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_logits(logits, lengths, params):\n",
    "    if len(tf.shape(lengths).shape) == 1:\n",
    "        lengths = tf.reshape(lengths, [1])\n",
    "    else:\n",
    "        lengths = tf.squeeze(lengths)\n",
    "        \n",
    "    # input size [max_time x batch_size x num_classes]\n",
    "    # CTC Word Beam Search Decoding Algorithm for predict words instead letters need here\n",
    "    # Word Beam Search: A Connectionist Temporal Classification Decoding Algorithm\n",
    "    decoded, _ = tf.nn.ctc_beam_search_decoder(tf.transpose(logits, (1, 0, 2)), lengths, merge_repeated=True)\n",
    "    \n",
    "    # decoded[j] containing the decoded outputs, j=0 in our case\n",
    "    codes = tf.cast(decoded[0], tf.int32)\n",
    "    \n",
    "    text = decode_codes(codes, params)\n",
    "    \n",
    "    return text, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpectrogram(tf.layers.Layer):\n",
    "    def __init__(self, sr, n_fft, frame_step, n_mel, fmin, fmax, **kwargs):\n",
    "        super(MelSpectrogram, self).__init__(**kwargs)\n",
    "        \n",
    "        self.sr = sr\n",
    "        self.n_fft = n_fft\n",
    "        self.frame_step = frame_step\n",
    "        self.n_mel = n_mel\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        \n",
    "    def call(self, signal):\n",
    "        # Short-time Fourier Transform\n",
    "        stft = tf.contrib.signal.stft(signal, self.n_fft, self.frame_step, self.n_fft, pad_end=False)\n",
    "        # magn_spectr = tf.abs(stft) maybe\n",
    "        pow_spectr = tf.real(stft * tf.conj(stft)) # necessary tf.real()? TODO: check this\n",
    "        \n",
    "        mel = tf.constant(np.transpose(librosa.filters.mel(self.sr, self.n_fft+1, self.n_mel, \n",
    "                                                           self.fmin, self.fmax)),\n",
    "                         dtype=tf.float32)\n",
    "\n",
    "        mel_spectr = tf.tensordot(pow_spectr, mel, 1)\n",
    "        mel_spectr.set_shape(pow_spectr.shape[:-1].concatenate(mel.shape[-1:]))\n",
    "       \n",
    "        # This helps to balance the importance of\n",
    "        # detail in low and high energy regions of the spectrum, which more closely\n",
    "        # matches human auditory sensitivity.\n",
    "        mel_spectr = tf.log(mel_spectr + 1e-6)\n",
    "        \n",
    "        return mel_spectr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(tf.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, \n",
    "                 dilation_rate, use_bias=True, \n",
    "                 kernel_initializer=tf.glorot_normal_initializer(), \n",
    "                 pad_valid=True, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "    \n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.pad_valid = pad_valid\n",
    "        \n",
    "        # Bidirectional Convolutional LSTM\n",
    "#         self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.ConvLSTM2D(filters, kernel_size, dilation_rate=dilation_rate, \n",
    "#                                         padding='valid', use_bias=use_bias, \n",
    "#                                         kernel_initializer=kernel_initializer, return_sequences=True))\n",
    "        self.lstm = tf.layers.Conv1D(filters, kernel_size, dilation_rate=dilation_rate, \n",
    "                                    padding='valid', use_bias=use_bias, \n",
    "                                    kernel_initializer=kernel_initializer)\n",
    "    def call(self, inputs):\n",
    "        if self.pad_valid:\n",
    "            padding = (self.kernel_size - 1) * self.dilation_rate\n",
    "            inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)\n",
    "        \n",
    "        return self.lstm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(tf.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, \n",
    "                 dilation_rate, pad_valid=True, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        \n",
    "        self.lstm1 = BiLSTM(filters, kernel_size, dilation_rate, pad_valid=pad_valid)\n",
    "        self.lstm2 = BiLSTM(filters, kernel_size, dilation_rate, pad_valid=pad_valid)\n",
    "        #self.out = tf.keras.layers.Bidirectional(tf.keras.layers.ConvLSTM2D(filters, kernel_size=1))\n",
    "        self.out = tf.layers.Conv1D(filters=filters, kernel_size=1)\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        data = tf.layers.batch_normalization(inputs, training=training)\n",
    "        \n",
    "        filters = self.lstm1(data)\n",
    "        gates = self.lstm2(data)\n",
    "            \n",
    "        filters = tf.nn.tanh(filters)\n",
    "        gates = tf.nn.sigmoid(gates)\n",
    "        \n",
    "        out = tf.nn.tanh(self.out(filters * gates))\n",
    "\n",
    "        return out + inputs, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResStack(tf.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, dilation_rates, pad_valid=True, **kwargs):\n",
    "        super(ResStack, self).__init__(**kwargs)\n",
    "        \n",
    "        self.blocks = [Residual(filters, kernel_size, dilation_rate, pad_valid) \n",
    "                      for dilation_rate in dilation_rates]\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        data = inputs\n",
    "        skip = 0\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            data, current_skip = block(data, training=training)\n",
    "            skip += current_skip\n",
    "        \n",
    "        return skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechNet(tf.layers.Layer):\n",
    "    def __init__(self, params, **kwargs):\n",
    "        super(SpeechNet, self).__init__(**kwargs)\n",
    "        \n",
    "        self.mel = MelSpectrogram(params['sampling_rate'], params['n_fft'], \n",
    "                                 params['frame_step'], params['n_mel'], params['fmin'], \n",
    "                                 params['fmax'])\n",
    "       \n",
    "       #self.exp = tf.keras.layers.Bidirectional(\n",
    "           #  tf.keras.layers.ConvLSTM2D(filters=params['stack_filters'], kernel_size=1, padding='same'))\n",
    "        \n",
    "        self.exp = tf.layers.Conv1D(filters=params['stack_filters'], kernel_size=1, padding='same')\n",
    "        \n",
    "        self.stacks = [ResStack(filters=params['stack_filters'], kernel_size=params['stack_kernel_size'],\n",
    "                dilation_rates=params['stack_dilation_rates'])\n",
    "            for _ in range(params['stacks'])]\n",
    "        \n",
    "        #self.out = tf.keras.layers.Bidirectional(\n",
    "         #   tf.keras.layers.ConvLSTM2D(filters=len(params['alphabet']) + 1, kernel_size=1, padding='same'))\n",
    "        \n",
    "        self.out = tf.layers.Conv1D(filters=len(params['alphabet'])+1, kernel_size=1, padding='same')\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "        with tf.device(\"/gpu:0\"):\n",
    "            data = self.mel(inputs)\n",
    "            data = tf.layers.batch_normalization(data, training=training)\n",
    "\n",
    "            if len(data.shape) == 2:\n",
    "                data = tf.expand_dims(data, 0)\n",
    "\n",
    "            data = self.exp(data)\n",
    "\n",
    "            for stack in self.stacks:\n",
    "                data = stack(data, training=training)\n",
    "\n",
    "            data = tf.layers.batch_normalization(data, training=training)    \n",
    "\n",
    "        return self.out(data) + 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def input_fn(inp_dataset, params, load_wave_fn=load_wave):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        def _input_fn():\n",
    "            dataset = inp_dataset\n",
    "\n",
    "            def generator_fn():\n",
    "                pool = Pool()\n",
    "                buffer = []\n",
    "                l = 0\n",
    "\n",
    "                for epoch in range(params['epochs']):\n",
    "                    dataset = inp_dataset\n",
    "\n",
    "\n",
    "                    for _, row in dataset.iterrows():\n",
    "                        l += 1\n",
    "                        if (l<1000 and l%10==0):\n",
    "                            print(row)\n",
    "                            print(row.text)\n",
    "\n",
    "                        if (l % 1000 == 0):\n",
    "                            print(row)\n",
    "                            print(row.text)\n",
    "\n",
    "                        buffer.append((row, params))\n",
    "\n",
    "                        if len(buffer) >= params['batch_size']:\n",
    "                            if params['parallelize']:\n",
    "                                audios = pool.map(load_wave_fn, buffer)\n",
    "                            else: \n",
    "                                audios = map(load_wave_fn, buffer)\n",
    "\n",
    "                            for audio, row in audios:\n",
    "                                if audio is not None:\n",
    "                                    if np.isnan(audio).any():\n",
    "                                        print('SKIP')\n",
    "                                    else:\n",
    "                                        yield (audio, len(audio)), row.text.encode()\n",
    "\n",
    "                            buffer = []\n",
    "\n",
    "    #         return tf.data.Dataset.from_generator(generator_fn, output_types=((tf.float32, tf.int32), \n",
    "    #                                                                          (tf.string)),\n",
    "    #                                              output_shapes=((None,()), (()))).padded_batch(\n",
    "    #         batch_size=params['batch_size'], padded_shapes=(tf.TensorShape([None]), tf.TensorShape(()),\n",
    "    #                                                        tf.TensorShape(())))\n",
    "            return tf.data.Dataset.from_generator(\n",
    "                    generator_fn,\n",
    "                    output_types=((tf.float32, tf.int32), (tf.string)),\n",
    "                    output_shapes=((None,()), (()))\n",
    "                ) \\\n",
    "                .padded_batch(\n",
    "                    batch_size=params['batch_size'],\n",
    "                    padded_shapes=(\n",
    "                        (tf.TensorShape([None]), tf.TensorShape(())),\n",
    "                        tf.TensorShape(())\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        if isinstance(features, dict):\n",
    "            original_lengths = features['length']\n",
    "        else: \n",
    "            audio, original_lengths = features\n",
    "\n",
    "        lengths = sequenceLength(original_lengths, params)\n",
    "\n",
    "        if labels is not None:\n",
    "            codes = encode_labels(labels, params)\n",
    "\n",
    "        network = SpeechNet(params)\n",
    "        is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "        print('Is training? {}'.format(is_training))\n",
    "\n",
    "        logits = network(audio, training=is_training)\n",
    "        text, predicted_codes = decode_logits(logits, lengths, params)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            predictions = {'logits': logits, 'text': tf.sparse_tensor_to_dense(text, '')}\n",
    "            export_outputs = {'predictions': tf.estimator.export.PredictOutput(predictions)}\n",
    "\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions, \n",
    "                                              export_outputs=export_outputs)\n",
    "        else:\n",
    "            loss = tf.reduce_mean(tf.nn.ctc_loss(labels=codes, inputs=logits,\n",
    "                                                sequence_length=lengths, time_major=False,\n",
    "                                                ignore_longer_outputs_than_inputs=True))\n",
    "            mean_edit_distance = tf.reduce_mean(tf.edit_distance(tf.cast(predicted_codes, tf.int32),\n",
    "                                                                 codes))\n",
    "            distance_metric = tf.metrics.mean(mean_edit_distance)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.EVAL:\n",
    "                return tf.estimator.EstimatorSpec(mode, loss=loss, \n",
    "                                                  eval_metric_ops={'edit_distance': distance_metric})\n",
    "            elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "                tf.summary.text('train_predicted_text', tf.sparse_tensor_to_dense(text, ''))\n",
    "                tf.summary.scalar('train_edit_distance', mean_edit_distance)\n",
    "\n",
    "                update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "                with tf.control_dependencies(update_ops):\n",
    "                    train_op = tf.contrib.layers.optimize_loss(loss=loss, global_step=global_step,\n",
    "                                                              learning_rate=params['lr'],\n",
    "                                                              optimizer=(params['optimizer']),\n",
    "                                                              update_ops=update_ops,\n",
    "                                                              clip_gradients=params['clip_gradients'],\n",
    "                                                              summaries=[\"learning_rate\", \"loss\",\n",
    "                                                                        \"global_gradient_norm\"])\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_params(batch_size=32,\n",
    "                   epochs=50000,\n",
    "                   parallelize=True,\n",
    "                   max_text_length=None,\n",
    "                   min_text_length=None,\n",
    "                   max_wave_length=80000,\n",
    "                   shuffle=True,\n",
    "                   random_shift_min=-4000,\n",
    "                   random_shift_max= 4000,\n",
    "                   random_stretch_min=0.7,\n",
    "                   random_stretch_max= 1.3,\n",
    "                   random_noise=0.75,\n",
    "                   random_noise_factor_min=0.2,\n",
    "                   random_noise_factor_max=0.5,\n",
    "                   augment=False):\n",
    "    return {\n",
    "        'parallelize': parallelize,\n",
    "        'shuffle': shuffle,\n",
    "        'max_text_length': max_text_length,\n",
    "        'min_text_length': min_text_length,\n",
    "        'max_wave_length': max_wave_length,\n",
    "        'random_shift_min': random_shift_min,\n",
    "        'random_shift_max': random_shift_max,\n",
    "        'random_stretch_min': random_stretch_min,\n",
    "        'random_stretch_max': random_stretch_max,\n",
    "        'random_noise': random_noise,\n",
    "        'random_noise_factor_min': random_noise_factor_min,\n",
    "        'random_noise_factor_max': random_noise_factor_max,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'augment': augment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_params(data,\n",
    "                      optimizer='Adam',\n",
    "                      lr=1e-4,\n",
    "                      alphabet=\" 'abcdefghijklmnopqrstuvwxyz\",\n",
    "                      pad_conv=True,\n",
    "                      stack_dilation_rates= [1, 3, 9, 27, 81],\n",
    "                      stacks=2,\n",
    "                      stack_kernel_size= 3,\n",
    "                      stack_filters= 32,\n",
    "                      sampling_rate=16000,\n",
    "                      n_fft=160*4,\n",
    "                      frame_step=160,\n",
    "                      fmin=0,\n",
    "                      fmax=8000,\n",
    "                      n_mel=160,\n",
    "                      clip_gradients=None,\n",
    "                      codename='regular',\n",
    "                      **kwargs):\n",
    "    params = {\n",
    "        'optimizer': optimizer,\n",
    "        'lr': lr,\n",
    "        'data': data,\n",
    "        'alphabet': alphabet,\n",
    "        'pad_conv': pad_conv,\n",
    "        'stack_dilation_rates': stack_dilation_rates,\n",
    "        'stacks': stacks,\n",
    "        'stack_kernel_size': stack_kernel_size,\n",
    "        'stack_filters': stack_filters,\n",
    "        'sampling_rate': sampling_rate,\n",
    "        'n_fft': n_fft,\n",
    "        'frame_step': frame_step,\n",
    "        'fmin': fmin,\n",
    "        'fmax': fmax,\n",
    "        'n_mel': n_mel,\n",
    "        'clip_gradients': clip_gradients,\n",
    "        'codename': codename\n",
    "    }\n",
    "    \n",
    "    #import pdb; pdb.set_trace()\n",
    "    \n",
    "    if kwargs is not None and 'data' in kwargs:\n",
    "        params['data'] = { **params['data'], **kwargs['data'] }\n",
    "        del kwargs['data']\n",
    "        \n",
    "    if kwargs is not None:\n",
    "        params = { **params, **kwargs }\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_name(params, excluded_keys=['alphabet', 'data', 'lr', 'clip_gradients']):\n",
    "\n",
    "    def represent(key, value):\n",
    "        if key in excluded_keys:\n",
    "            return None\n",
    "        else:\n",
    "            if isinstance(value, list):\n",
    "                return '{}_{}'.format(key, '_'.join([str(v) for v in value]))\n",
    "            else:\n",
    "                return '{}_{}'.format(key, value)\n",
    "\n",
    "    parts = filter(\n",
    "        lambda p: p is not None,\n",
    "        [\n",
    "            represent(k, params[k])\n",
    "            for k in sorted(params.keys())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return '/'.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def experiment(data_params=dataset_params(), **kwargs):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        params = experiment_params(\n",
    "            data_params,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        print(params)\n",
    "\n",
    "        estimator = tf.estimator.Estimator(\n",
    "            model_fn=model_fn,\n",
    "            model_dir='/content/',\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        #import pdb; pdb.set_trace()\n",
    "\n",
    "        train_spec = tf.estimator.TrainSpec(\n",
    "            input_fn=input_fn(\n",
    "                train_data,\n",
    "                params['data']\n",
    "            )\n",
    "        )\n",
    "\n",
    "        features = {\n",
    "            \"audio\": tf.placeholder(dtype=tf.float32, shape=[None]),\n",
    "            \"length\": tf.placeholder(dtype=tf.int32, shape=[])\n",
    "        }\n",
    "\n",
    "        serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(\n",
    "            features\n",
    "        )\n",
    "\n",
    "        best_exporter = tf.estimator.BestExporter(\n",
    "          name=\"best_exporter\",\n",
    "          serving_input_receiver_fn=serving_input_receiver_fn,\n",
    "          exports_to_keep=5\n",
    "        )\n",
    "\n",
    "        eval_params = copy.deepcopy(params['data'])\n",
    "        eval_params['augment'] = False\n",
    "\n",
    "        eval_spec = tf.estimator.EvalSpec(\n",
    "            input_fn=input_fn(\n",
    "                eval_data,\n",
    "                eval_params\n",
    "            ),\n",
    "            throttle_secs=60*30,\n",
    "            exporters=best_exporter\n",
    "        )\n",
    "\n",
    "        tf.estimator.train_and_evaluate(\n",
    "            estimator,\n",
    "            train_spec,\n",
    "            eval_spec\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': 'Momentum', 'lr': 0.001, 'data': {'parallelize': True, 'shuffle': True, 'max_text_length': None, 'min_text_length': None, 'max_wave_length': 320000, 'random_shift_min': -4000, 'random_shift_max': 4000, 'random_stretch_min': 0.8, 'random_stretch_max': 1.2, 'random_noise': 0.75, 'random_noise_factor_min': 0.1, 'random_noise_factor_max': 0.15, 'epochs': 1, 'batch_size': 18, 'augment': False}, 'alphabet': ' !\"&\\',-.01234:;\\\\abcdefghijklmnopqrstuvwxyz', 'pad_conv': True, 'stack_dilation_rates': [1, 3], 'stacks': 6, 'stack_kernel_size': 7, 'stack_filters': 384, 'sampling_rate': 16000, 'n_fft': 1280, 'frame_step': 640, 'fmin': 0, 'fmax': 8000, 'n_mel': 160, 'clip_gradients': 20.0, 'codename': 'deep_max_20_seconds', 'causal_convolutions': False}\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/content/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C699D85FD0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Is training? True\n",
      "WARNING:tensorflow:From C:\\Users\\higer\\AppData\\Local\\conda\\conda\\envs\\DL2\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /content/model.ckpt.\n",
      "filename                       cv-valid-train/sample-000009.mp3\n",
      "text          when he speaks in our language i can interpret...\n",
      "up_votes                                                      1\n",
      "down_votes                                                    0\n",
      "age                                                         NaN\n",
      "gender                                                      NaN\n",
      "accent                                                      NaN\n",
      "duration                                                    NaN\n",
      "Name: 9, dtype: object\n",
      "when he speaks in our language i can interpret what he has said\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "pred_t = True\n",
    "sess.run(experiment(\n",
    "    dataset_params(\n",
    "        batch_size=18,\n",
    "        epochs=1,\n",
    "        max_wave_length=320000,\n",
    "        augment=False,\n",
    "        random_noise=0.75,\n",
    "        random_noise_factor_min=0.1,\n",
    "        random_noise_factor_max=0.15,\n",
    "        random_stretch_min=0.8,\n",
    "        random_stretch_max=1.2\n",
    "    ),\n",
    "    codename='deep_max_20_seconds',\n",
    "    alphabet=' !\"&\\',-.01234:;\\\\abcdefghijklmnopqrstuvwxyz', # !\"&',-.01234:;\\abcdefghijklmnopqrstuvwxyz\n",
    "    causal_convolutions=False,\n",
    "    stack_dilation_rates=[1, 3],\n",
    "    stacks=6,\n",
    "    stack_kernel_size=7,\n",
    "    stack_filters=3*128,\n",
    "    n_fft=160*8,\n",
    "    frame_step=160*4,\n",
    "    n_mel=160,\n",
    "    optimizer='Momentum',\n",
    "    lr=0.001,\n",
    "    clip_gradients=20.0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
